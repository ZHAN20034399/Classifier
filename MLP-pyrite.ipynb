{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aaa3f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "from typing import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c4628",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_path = r\"D:\\cddvd\\LA_knn_pyrite.xlsx\"#Please enter the path to the Supplementary data 4\n",
    "data = pd.read_excel(file_path)\n",
    "df = data.loc[:, [\"Deposit type\", \"Co\", \"Ni\",\"Zn\", \"Cu\", \"Sb\", \"Pb\", \"Ag\", \"Se\",\"As\",\"Bi\"]]\n",
    "# Print class distribution of the original dataset\n",
    "print(\"Class distribution of the original dataset:\")\n",
    "print(y.value_counts())\n",
    "X = df.drop(\"Deposit type\", axis=1)  # Features\n",
    "y = df[\"Deposit type\"]  # Target variable\n",
    "# Check for missing values in the target variable and handle them\n",
    "if y.isnull().values.any():\n",
    "    y.dropna(inplace=True)\n",
    "    X = X.loc[y.index]  \n",
    "X.dropna(inplace=True)\n",
    "y = y.loc[X.index]\n",
    "print(\"Class distribution after removing missing values:\")\n",
    "print(y.value_counts())\n",
    "y = pd.Categorical(y)\n",
    "y = y.codes\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "print(\"Class distribution of the training set after splitting:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# Cross-validation performance of the MLP classifier\n",
    "models = (MLPClassifier(alpha=0.5),)\n",
    "\n",
    "for clf in models:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "    print(f'{clf.__class__.__name__}: {scores.mean():2.2f}±{scores.std():2.2f}')\n",
    "\n",
    "# Create a pipeline with a scaler and MLPClassifier\n",
    "pipe_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlpclassifier\", MLPClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter optimization\n",
    "alpha_range = np.logspace(-4, 1, 6, base=10)\n",
    "param_grid = {\n",
    "    \"mlpclassifier__hidden_layer_sizes\": [(50,), (50, 50)], \n",
    "    \"mlpclassifier__solver\": ['adam'], \n",
    "    \"mlpclassifier__max_iter\": [200],  \n",
    "    \"mlpclassifier__alpha\": alpha_range,  \n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid = GridSearchCV(\n",
    "    pipe_clf, param_grid=param_grid, \n",
    "    cv=5, scoring=\"f1_macro\", n_jobs=-1, refit=True, verbose=2\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\" % (grid.best_params_, grid.best_score_))\n",
    "y_test_pred = grid.predict(X_test)\n",
    "t_train_pred = grid.predict(X_train)\n",
    "y_test_proba = grid.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "print(classification_report(y_train, t_train_pred))\n",
    "print(classification_report(y_test, y_test_pred, output_dict=False))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "report_filename = r\"D:\\cddvd\\MLPpyrite_report.txt\"  # Specify the file path and name\n",
    "with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Training set report:\\n\")\n",
    "    f.write(classification_report(y_train, t_train_pred))\n",
    "    f.write(\"\\nTest set report:\\n\")\n",
    "    f.write(classification_report(y_test, y_test_pred, output_dict=False))\n",
    "    f.write(\"\\nConfusion Matrix:\\n\")\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    f.write(str(cm))\n",
    "\n",
    "print(f\"Classification report and confusion matrix have been saved to: {report_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trained MLPClassifier instance from the grid search\n",
    "mlp = grid.best_estimator_.named_steps[\"mlpclassifier\"]\n",
    "\n",
    "# Define a prediction function using the trained model\n",
    "def predict_function(X):\n",
    "    return mlp.predict_proba(X)\n",
    "\n",
    "# Create a SHAP explainer using KernelExplainer\n",
    "explainer = shap.KernelExplainer(predict_function, X_train)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Define custom colors for the plot\n",
    "light_colors = [(0.6, 0.86, 0.88), (1, 0.9, 0.73)]\n",
    "custom_cmap = ListedColormap(light_colors)\n",
    "\n",
    "# Plot SHAP Bee Swarm plots for each class\n",
    "for i, class_name in enumerate(['SEDEX', 'VMS']):\n",
    "    # Convert shap_values to an Explanation object\n",
    "    shap_exp = shap.Explanation(\n",
    "        base_values=explainer.expected_value,\n",
    "        values=shap_values[i],\n",
    "        data=X_train,\n",
    "        feature_names=X_train.columns\n",
    "    )\n",
    "    \n",
    "    # Plot SHAP Bee Swarm plot for the current class with custom colors\n",
    "    shap.plots.beeswarm(shap_exp, max_display=10, color=custom_cmap)  # Display top 10 features\n",
    "    plt.title(f'SHAP Bee Swarm Plot for {class_name}')\n",
    "    \n",
    "    # Save the SHAP plot as a JPG image\n",
    "    plt.savefig(f'D:/cddvd/SHAP_beeswarm_{class_name}.jpg', dpi=600, format='jpg')\n",
    "    plt.close()  # Close the plot to avoid overlapping with the next one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "label_order = [\"SEDEX\", \"VMS\"]\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "cm_df = pd.DataFrame(cm, columns=label_order, index=label_order)\n",
    "cm_df_percentage = cm_df.div(cm_df.sum(axis=0), axis=1) * 100\n",
    "plt.figure(figsize=(2.5, 2.5))\n",
    "plt.rc('font', family='Times New Roman', size=8)\n",
    "ax = sns.heatmap(cm_df, linewidths=.5, ax=plt.gca(), cmap=\"Blues\")\n",
    "norm = plt.Normalize(vmin=cm_df.values.min(), vmax=cm_df.values.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=norm)\n",
    "for i in range(len(cm_df)):\n",
    "    for j in range(len(cm_df)):\n",
    "        value = cm_df.iloc[i, j]\n",
    "        percentage = cm_df_percentage.iloc[i, j]\n",
    "        # Choose text color based on the background color of the cell\n",
    "        color = 'white' if sm.to_rgba(value)[0:3] < (0.5, 0.5, 0.5) else 'black'\n",
    "        plt.text(j + 0.5, i + 0.5, f\"{value}\\n{percentage:.1f}%\",\n",
    "                 ha='center', va='center', color=color, family='Times New Roman', size=8)\n",
    "plt.title(\"Test set confusion matrix (MLP)\", fontsize=8)\n",
    "plt.xlabel(\"Predictions\", fontsize=8)\n",
    "plt.ylabel(\"True labels\", fontsize=8)\n",
    "ax.set_xticklabels(label_order, rotation=45, fontsize=8)\n",
    "ax.set_yticklabels(label_order, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'D:\\cddvd\\confusion_matrix_MLP_pyrite.svg', dpi=600, format='svg')\n",
    "plt.savefig(r'D:\\cddvd\\confusion_matrix_MLP_pyrite.pdf', dpi=600, format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3aeaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "RF classifier to predict the genetic classes of the chalcopyrite source with \"Co\", \"Ni\", \"Cu\",\"Zn\", \"Sb\", \"Pb\", \"Ag\", \"Se\", \"As\",\"Bi\"values,\n",
    "Please enter the path of the .xlsx data file.(for example: /path/to/file/example_data.xlsx )\n",
    "The data are supposed to contain all the 10 features above for prediction.\n",
    "If any one of the features is missing in a sample, that sample will be discarded.\n",
    "The columns' names of Co, Ni,Cu, Zn, As, Sb, Pb, Ag, Se,Bi should be exactly as listed above without any prefix and suffix\n",
    "and MAKE SURE this column name row is the FIRST row.\n",
    "\"\"\"\n",
    ")\n",
    "data_file_path = r\"D:\\我的论文\\dongshengmiao_knn_pyrite.xlsx\"#Please enter the path to the data file\n",
    "df = pd.read_excel(data_file_path)\n",
    "index = ['SEDEX', 'VMS']\n",
    "print(df)\n",
    "elements = [ \"Co\", \"Ni\",\"Zn\", \"Cu\", \"Sb\", \"Pb\", \"Ag\", \"Se\",\"As\",\"Bi\"]\n",
    "\n",
    "for element in elements:\n",
    "    df[element] = pd.to_numeric(df[element], errors=\"coerce\")\n",
    "\n",
    "to_predict = df.loc[:, elements].dropna()\n",
    "to_predict.reset_index(drop=True, inplace=True)\n",
    "print(f\"{to_predict.shape[0]} samples available\")\n",
    "print(to_predict.describe())\n",
    "predict_res = grid.predict(to_predict)\n",
    "predict_res = list(predict_res)\n",
    "for i, ind in enumerate(predict_res):\n",
    "    predict_res[i] = index[ind]\n",
    "\n",
    "c: Counter[str] = Counter(predict_res)\n",
    "if not c:\n",
    "    input(\"no sample with the 10 features detected!\")\n",
    "    raise SystemExit()\n",
    "    \n",
    "proba = grid.predict_proba(to_predict)\n",
    "predict_res = np.array(predict_res)\n",
    "predict_res = predict_res.reshape((predict_res.shape[0], 1))\n",
    "res = np.concatenate([predict_res, proba], axis=1)\n",
    "res = pd.DataFrame(res, columns=['pred_pyrite_type', 'SEDEX_proba', 'VMS_proba'])\n",
    "pd.set_option('display.max_columns', 10)\n",
    "print('Detailed report preview:\\n', res)\n",
    "\n",
    "print(\"The samples are predicted respectively to be: \")\n",
    "print(c.most_common(), \"\\n\")\n",
    "print(\n",
    "    f\"The most possible type of the group of samples is: {c.most_common(1)[0][0]}.\\n\"\n",
    ")\n",
    "\n",
    "if input('Save report? (y/n): ').lower() == 'y':\n",
    "    base_filename = os.path.basename(data_file_path)\n",
    "    prefix, _ = os.path.splitext(base_filename)\n",
    "    save_name = prefix + '_resultMLPpyrite.xlsx'\n",
    "    res2 = pd.concat([to_predict['Pb'], res], axis=1, )\n",
    "    output = df.join(res2.set_index('Pb'), on='Pb')\n",
    "    output.to_excel(save_name)\n",
    "    print(f'{save_name} saved.')\n",
    "input(\"Press any key to exit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
