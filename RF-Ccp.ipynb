{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shap\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "from typing import Counter\n",
    "import matplotlib.colors as mcolors\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from openpyxl import Workbook\n",
    "import matplotlib\n",
    "import shap\n",
    "from matplotlib.colors import ListedColormap\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f6036",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_path = r\"D:\\cddvd\\sedex_vms_zhong.xlsx\"#Please enter the path to the Supplementary data 3\n",
    "data = pd.read_excel(file_path)\n",
    "df = data.loc[:, [\"Deposit type\", \"Co\", \"Ni\", \"Zn\", \"Cd\", \"Sb\", \"Pb\", \"Ag\", \"Se\"]]\n",
    "X = df.copy(deep=True)\n",
    "y = X.pop('Deposit type')\n",
    "\n",
    "# Print the original dataset class distribution\n",
    "print(\"Original dataset class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "if y.isnull().values.any():\n",
    "    y.dropna(inplace=True)\n",
    "    X = X.loc[y.index]  \n",
    "    print(\"X and y lengths:\", X.shape[0], y.shape[0])\n",
    "\n",
    "if X.isnull().values.any():\n",
    "    X.dropna(inplace=True)\n",
    "    y = y.loc[X.index]\n",
    "\n",
    "# Print class distribution after removing missing values\n",
    "print(\"Class distribution after missing values removal:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Factorize the target variable\n",
    "y_int, index = pd.factorize(y, sort=True)\n",
    "y = y_int\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "print(\"Training set class distribution after split:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "if X.isnull().values.any():\n",
    "    X.dropna(inplace=True)\n",
    "    y = y.loc[X.index]  \n",
    "\n",
    "models = (RandomForestClassifier(),)\n",
    "for clf in models:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "    print(f'{scores.mean():2.2f} Â± {scores.std():2.2f}')\n",
    "\n",
    "pipe_clf = make_pipeline(RandomForestClassifier(oob_score=True, random_state=10, class_weight='balanced'))\n",
    "\n",
    "param_grid = {\n",
    "    \"randomforestclassifier__n_estimators\": [130],\n",
    "    \"randomforestclassifier__max_depth\": [11],\n",
    "    \"randomforestclassifier__min_samples_leaf\": [3],\n",
    "    \"randomforestclassifier__min_samples_split\": [5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe_clf, param_grid=param_grid, cv=10, scoring=\"f1_macro\", n_jobs=-1, refit=True)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: %s, score: %0.2f\" % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "y_test_pred = grid.predict(X_test)\n",
    "t_train_pred = grid.predict(X_train)\n",
    "y_test_proba = grid.predict_proba(X_test)[:, 1]\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_train, t_train_pred))\n",
    "print(classification_report(y_test, y_test_pred, output_dict=False))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "# Print classification report and confusion matrix for the test set\n",
    "print(classification_report(y_test, y_test_pred, output_dict=False))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Final evaluation\n",
    "print(classification_report(y_test, y_test_pred, output_dict=False))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "report_filename = r\"D:\\cddvd\\RFpyrite_report.txt\"\n",
    "with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Training set report:\\n\")\n",
    "    f.write(classification_report(y_train, t_train_pred))\n",
    "    \n",
    "    f.write(\"\\nTest set report:\\n\")\n",
    "    f.write(classification_report(y_test, y_test_pred, output_dict=False))\n",
    "    \n",
    "    f.write(\"\\nConfusion Matrix:\\n\")\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    f.write(str(cm))\n",
    "\n",
    "print(f\"Classification report and confusion matrix saved to: {report_filename}\")\n",
    "best_rf_model = grid.best_estimator_.named_steps['randomforestclassifier']\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.Explainer(best_rf_model, X_train)\n",
    "shap_values_train = explainer.shap_values(X_train)\n",
    "\n",
    "# Create DataFrame for each class\n",
    "shap_values_df_train_0 = pd.DataFrame(shap_values_train[0], columns=X_train.columns, index=X_train.index)\n",
    "shap_values_df_train_1 = pd.DataFrame(shap_values_train[1], columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "output_path_train = 'D:/cddvd/shapvalue_train_rfccp.xlsx'\n",
    "with pd.ExcelWriter(output_path_train, engine='xlsxwriter') as writer:\n",
    "    shap_values_df_train_0.to_excel(writer, sheet_name='Class_SEDEX')\n",
    "    shap_values_df_train_1.to_excel(writer, sheet_name='Class_VMS')\n",
    "\n",
    "print(f\"SHAP values for the training set successfully saved to {output_path_train}\")\n",
    "\n",
    "# Set font and size\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 8\n",
    "\n",
    "shap_abs_values_train = [np.abs(values) for values in shap_values_train]\n",
    "mean_shap_values_train = [np.mean(np.abs(shap_values_train[i]), axis=0) for i in range(len(shap_values_train))]\n",
    "\n",
    "output_path_mean_train = 'D:/cddvd/shapvalue_mean_train_rfccp.xlsx'\n",
    "mean_shap_df_train = pd.DataFrame(mean_shap_values_train, columns=X_train.columns)\n",
    "mean_shap_df_train.to_excel(output_path_mean_train, index=False)\n",
    "\n",
    "print(f\"Mean SHAP values for the training set successfully saved to {output_path_mean_train}\")\n",
    "\n",
    "shap.plots.beeswarm(shap.Explanation(values=shap_values_train[0], base_values=explainer.expected_value, \n",
    "                                      data=X_train, feature_names=X_train.columns),\n",
    "                                      max_display=10, show=False)\n",
    "\n",
    "# Save SHAP figure\n",
    "plt.savefig('D:/cddvd/SHAP_RF_pyrite.jpg', dpi=600, format='jpg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Export the test set\n",
    "test_results_df = pd.DataFrame(X_test)\n",
    "test_results_df['Actual'] = y_test\n",
    "test_results_df['Predicted'] = y_test_pred\n",
    "output_file_path = r\"D:\\cddvd\\test_set_results_Ccp.xlsx\"\n",
    "test_results_df.to_excel(output_file_path, index=False, header=True)\n",
    "\n",
    "print(f\"Test set results have been successfully saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777dd59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "label_order = [\"SEDEX\", \"VMS\"]\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "cm_df = pd.DataFrame(cm, columns=label_order, index=label_order)\n",
    "cm_df_percentage = cm_df.div(cm_df.sum(axis=0), axis=1) * 100\n",
    "plt.figure(figsize=(2.5, 2.5))\n",
    "plt.rc('font', family='Times New Roman', size=8)\n",
    "ax = sns.heatmap(cm_df, linewidths=.5, ax=plt.gca(), cmap=\"Blues\")\n",
    "norm = plt.Normalize(vmin=cm_df.values.min(), vmax=cm_df.values.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=norm)\n",
    "\n",
    "# Manually add text to each cell\n",
    "for i in range(len(cm_df)):\n",
    "    for j in range(len(cm_df)):\n",
    "        value = cm_df.iloc[i, j]\n",
    "        percentage = cm_df_percentage.iloc[i, j]\n",
    "        color = 'white' if sm.to_rgba(value)[0:3] < (0.5, 0.5, 0.5) else 'black'\n",
    "        plt.text(j + 0.5, i + 0.5, f\"{value}\\n{percentage:.1f}%\",\n",
    "                 ha='center', va='center', color=color, family='Times New Roman', size=8)\n",
    "\n",
    "plt.title(\"Test set confusion matrix (RF)\", fontsize=8)\n",
    "plt.xlabel(\"Predictions\", fontsize=8)\n",
    "plt.ylabel(\"True labels\", fontsize=8)\n",
    "ax.set_xticklabels(label_order, rotation=45, fontsize=8)\n",
    "ax.set_yticklabels(label_order, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'D:\\cddvd\\confusion_matrix_RF_ccp.svg', dpi=600, format='svg')\n",
    "plt.savefig(r'D:\\cddvd\\confusion_matrix_RF_ccp.pdf', dpi=600, format='pdf')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ad948",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "RF classifier to predict the genetic classes of the chalcopyrite source with \"Co\", \"Ni\", \"Zn\", \"Sb\", \"Pb\", \"Ag\", \"Se\", \"Cd\"values,\n",
    "Please enter the path of the .xlsx data file.(for example: /path/to/file/example_data.xlsx )\n",
    "The data are supposed to contain all the 8 features above for prediction.\n",
    "If any one of the features is missing in a sample, that sample will be discarded.\n",
    "The columns' names of Co, Ni, Zn, Cd, Sb, Pb, Ag, Se should be exactly as listed above without any prefix and suffix\n",
    "and MAKE SURE this column name row is the FIRST row.\n",
    "\"\"\"\n",
    ")\n",
    "data_file_path =  r\"D:\\æçè®ºæ\\dongshengmiao_knn_ccp.xlsx\"#Please enter the path to the data file\n",
    "df = pd.read_excel(data_file_path, sheet_name='sheet1')\n",
    "\n",
    "index = ['SEDEX', 'VMS']\n",
    "print(df)\n",
    "elements = [ \"Co\", \"Ni\", \"Zn\", \"Cd\", \"Sb\", \"Pb\", \"Ag\", \"Se\"]\n",
    "\n",
    "for element in elements:\n",
    "    df[element] = pd.to_numeric(df[element], errors=\"coerce\")\n",
    "\n",
    "to_predict = df.loc[:, elements].dropna()\n",
    "to_predict.reset_index(drop=True, inplace=True)\n",
    "print(f\"{to_predict.shape[0]} samples available\")\n",
    "print(to_predict.describe())\n",
    "predict_res = grid.predict(to_predict)\n",
    "predict_res = list(predict_res)\n",
    "for i, ind in enumerate(predict_res):\n",
    "    predict_res[i] = index[ind]\n",
    "\n",
    "c: Counter[str] = Counter(predict_res)\n",
    "if not c:\n",
    "    input(\"no sample with the 8 features detected!\")\n",
    "    raise SystemExit()\n",
    "    \n",
    "proba = grid.predict_proba(to_predict)\n",
    "predict_res = np.array(predict_res)\n",
    "predict_res = predict_res.reshape((predict_res.shape[0], 1))\n",
    "res = np.concatenate([predict_res, proba], axis=1)\n",
    "res = pd.DataFrame(res, columns=['pred_chalcopyrite_type', 'SEDEX_proba', 'VMS_proba'])\n",
    "pd.set_option('display.max_columns', 10)\n",
    "print('Detailed report preview:\\n', res)\n",
    "\n",
    "print(\"The samples are predicted respectively to be: \")\n",
    "print(c.most_common(), \"\\n\")\n",
    "print(\n",
    "    f\"The most possible type of the group of samples is: {c.most_common(1)[0][0]}.\\n\"\n",
    ")\n",
    "\n",
    "if input('Save report? (y/n): ').lower() == 'y':\n",
    "    base_filename = os.path.basename(data_file_path)\n",
    "    prefix, _ = os.path.splitext(base_filename)\n",
    "    save_name = prefix + '_resultrfccp.xlsx'\n",
    "    res2 = pd.concat([to_predict['Pb'], res], axis=1, )\n",
    "    output = df.join(res2.set_index('Pb'), on='Pb')\n",
    "    output.to_excel(save_name)\n",
    "    print(f'{save_name} saved.')\n",
    "input(\"Press any key to exit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
