{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from typing import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib\n",
    "from scipy.stats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1b88d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "file_path = \"D:\\cddvd\\sedex_vms_zhong.xlsx\"#Please enter the path to the Supplementary data 3\n",
    "data = pd.read_excel(file_path)\n",
    "df = data[['Deposit type', 'Co', 'Ni', 'Zn', 'Cd', 'Sb', 'Pb', 'Ag', 'Se']]\n",
    "X = df.copy(deep=True)\n",
    "y = X.pop('Deposit type')\n",
    "y_int, index = pd.factorize(y, sort=True)\n",
    "y = y_int\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Print class distribution\n",
    "print(y.value_counts())\n",
    "\n",
    "# Models to be used for training\n",
    "models = (\n",
    "    svm.SVC(kernel='linear', C=1),\n",
    "    svm.SVC(kernel='rbf', C=1)\n",
    ")\n",
    "\n",
    "# Cross-validation scores for each model\n",
    "for clf in models:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "    print(f'{scores.mean():2.2f} ± {scores.std():2.2f}')\n",
    "\n",
    "# Create a pipeline with SVC\n",
    "pipe_clf = make_pipeline(svm.SVC(cache_size=1000, class_weight=None, probability=True))\n",
    "\n",
    "# Define a custom normalizer class\n",
    "class MidpointNormalize(Normalizer):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        super().__init__(vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "# Set ranges for C and gamma parameters\n",
    "C_range = np.logspace(-2, 5, 8, base=10)\n",
    "gamma_range = np.logspace(-7, -2, 6, base=10)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    \"svc__kernel\": [\"rbf\"],\n",
    "    \"svc__gamma\": gamma_range,\n",
    "    \"svc__C\": C_range\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid = GridSearchCV(pipe_clf, param_grid=param_grid, cv=10, scoring=\"f1_macro\", n_jobs=-1, refit=True)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(f\"The best parameters are {grid.best_params_} with a score of {grid.best_score_:0.2f}\")\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"\\nCross-validation scores:\")\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(f\"{mean:0.3f} (+/-{std*2:0.03f}) for {params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = grid.predict(X_test)\n",
    "t_train_pred = grid.predict(X_train)\n",
    "y_test_proba = grid.predict_proba(X_test)[:, 1]\n",
    "# Print classification report for the training set\n",
    "print(\"Training set report:\")\n",
    "print(classification_report(y_train, t_train_pred))\n",
    "print(\"Test set report:\")\n",
    "print(classification_report(y_test, y_test_pred, output_dict=False))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "report_filename = r\"D:\\cddvd\\SVMccp_report.txt\"  # Specify the file path and name\n",
    "# Final evaluation on test set\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "print(classification_report(y_test, y_test_pred, output_dict=False))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a592129",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the trained SVC model from the grid search\n",
    "svc_model = grid.best_estimator_.named_steps[\"svc\"]\n",
    "\n",
    "# Define a prediction function using the trained SVC model\n",
    "def predict_function(X):\n",
    "    return svc_model.predict_proba(X)\n",
    "\n",
    "# Create a SHAP explainer using KernelExplainer\n",
    "explainer = shap.KernelExplainer(predict_function, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Plot SHAP Bee Swarm plots for each class\n",
    "for i, class_name in enumerate(['No Deposit', 'Deposit']):\n",
    "    shap_exp = shap.Explanation(\n",
    "        base_values=explainer.expected_value,\n",
    "        values=shap_values[i],\n",
    "        data=X_train,\n",
    "        feature_names=X_train.columns\n",
    "    )\n",
    "    shap.plots.beeswarm(shap_exp, max_display=10)  # Show top 10 features\n",
    "    plt.title(f'SHAP Bee Swarm Plot for {class_name}')\n",
    "    plt.savefig(f'D:/cddvd/SHAP_beeswarm_{class_name}.jpg', dpi=600, format='jpg')\n",
    "    plt.close()  # Close the current plot\n",
    "# Plot SHAP summary plot (showing feature impacts on predictions)\n",
    "shap.summary_plot(shap_values[1], X_train, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284f6ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define label order\n",
    "label_order = [\"SEDEX\", \"VMS\"]\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "cm_df = pd.DataFrame(cm, columns=label_order, index=label_order)\n",
    "cm_df_percentage = cm_df.div(cm_df.sum(axis=0), axis=1) * 100\n",
    "plt.figure(figsize=(2.5, 2.5))\n",
    "plt.rc('font', family='Times New Roman', size=8)\n",
    "ax = sns.heatmap(cm_df, linewidths=.5, ax=plt.gca(), cmap=\"Blues\")\n",
    "norm = plt.Normalize(vmin=cm_df.values.min(), vmax=cm_df.values.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=norm)\n",
    "\n",
    "for i in range(len(cm_df)):\n",
    "    for j in range(len(cm_df)):\n",
    "        value = cm_df.iloc[i, j]\n",
    "        percentage = cm_df_percentage.iloc[i, j]\n",
    "        color = 'white' if sm.to_rgba(value)[0:3] < (0.5, 0.5, 0.5) else 'black'  # Choose text color based on cell color\n",
    "        plt.text(j + 0.5, i + 0.5, f\"{value}\\n{percentage:.1f}%\",\n",
    "                 ha='center', va='center', color=color, family='Times New Roman', size=8)\n",
    "plt.title(\"Test set confusion matrix (SVM)\", fontsize=8)\n",
    "plt.xlabel(\"Predictions\", fontsize=8)\n",
    "plt.ylabel(\"True labels\", fontsize=8)\n",
    "\n",
    "ax.set_xticklabels(label_order, rotation=45, fontsize=8)\n",
    "ax.set_yticklabels(label_order, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'D:\\cddvd\\confusion_matrix_SVM_ccp.svg', dpi=600, format='svg')\n",
    "plt.savefig(r'D:\\cddvd\\confusion_matrix_SVM_ccp.pdf', dpi=600, format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8232a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "RF classifier to predict the genetic classes of the chalcopyrite source with \"Co\", \"Ni\", \"Zn\", \"Sb\", \"Pb\", \"Ag\", \"Se\", \"Cd\"values,\n",
    "Please enter the path of the .xlsx data file.(for example: /path/to/file/example_data.xlsx )\n",
    "The data are supposed to contain all the 8 features above for prediction.\n",
    "If any one of the features is missing in a sample, that sample will be discarded.\n",
    "The columns' names of Co, Ni, Zn, Cd, Sb, Pb, Ag, Se should be exactly as listed above without any prefix and suffix\n",
    "and MAKE SURE this column name row is the FIRST row.\n",
    "\"\"\"\n",
    ")\n",
    "data_file_path = r\"D:\\我的论文\\dongshengmiao_knn_ccp.xlsx\"#Please enter the path to the data file\n",
    "df = pd.read_excel(data_file_path)\n",
    "index = ['SEDEX', 'VMS']\n",
    "elements = [ \"Co\",\"Ni\",\"Zn\", \"Cd\", \"Sb\", \"Pb\",\"Ag\",\"Se\"]\n",
    "for element in elements:\n",
    "    df[element] = pd.to_numeric(df[element], errors=\"coerce\")\n",
    "\n",
    "to_predict = df.loc[:, elements].dropna()\n",
    "to_predict.reset_index(drop=True, inplace=True)\n",
    "print(f\"{to_predict.shape[0]} samples available\")\n",
    "print(to_predict.describe())\n",
    "predict_res = grid.predict(to_predict)\n",
    "predict_res = list(predict_res)\n",
    "for i, ind in enumerate(predict_res):\n",
    "    predict_res[i] = index[ind]\n",
    "\n",
    "c: Counter[str] = Counter(predict_res)\n",
    "if not c:\n",
    "    input(\"no sample with the 8 features detected!\")\n",
    "    raise SystemExit()\n",
    "    \n",
    "proba = grid.predict_proba(to_predict)\n",
    "predict_res = np.array(predict_res)\n",
    "predict_res = predict_res.reshape((predict_res.shape[0], 1))\n",
    "res = np.concatenate([predict_res, proba], axis=1)\n",
    "res = pd.DataFrame(res, columns=['pred_chalcopyrite_type', 'SEDEX_proba', 'VMS_proba'])\n",
    "pd.set_option('display.max_columns', 10)\n",
    "print('Detailed report preview:\\n', res)\n",
    "print(\"The samples are predicted respectively to be: \")\n",
    "print(c.most_common(), \"\\n\")\n",
    "print(\n",
    "    f\"The most possible type of the group of samples is: {c.most_common(1)[0][0]}.\\n\"\n",
    ")\n",
    "if input('Save report? (y/n): ').lower() == 'y':\n",
    "    base_filename = os.path.basename(data_file_path)\n",
    "    prefix, _ = os.path.splitext(base_filename)\n",
    "    save_name = prefix + '_resultSVMccp.xlsx'\n",
    "    res2 = pd.concat([to_predict['Pb'], res], axis=1, )\n",
    "    output = df.join(res2.set_index('Pb'), on='Pb')\n",
    "    output.to_excel(save_name)\n",
    "    print(f'{save_name} saved.')\n",
    "input(\"Press any key to exit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
